"""
ç»“æ„åŒ–æ—¥å¿—ç³»ç»Ÿ - æ”¯æŒJSONå’ŒMarkdownåŒå†™æ ¼å¼

å®ç°TradingAgentsä¼ä¸šçº§æ—¥å¿—æ¶æ„ï¼š
- JSONæ ¼å¼ï¼šæœºå™¨å¯è¯»ï¼Œä¾¿äºåˆ†æå’Œç›‘æ§
- Markdownæ ¼å¼ï¼šäººç±»å¯è¯»ï¼Œä¾¿äºè°ƒè¯•å’ŒæŠ¥å‘Š
- ç»Ÿä¸€çš„æ—¥å¿—æ¨¡å¼å’Œç»“æ„åŒ–å­—æ®µ
- ä¸ç°æœ‰InterpretableLoggeré›†æˆ
"""

import logging
import json
from typing import Dict, Any, List, Optional, Union
from datetime import datetime
from pathlib import Path
from dataclasses import dataclass, asdict
from enum import Enum
import traceback
import threading
from concurrent.futures import ThreadPoolExecutor
import queue

from ..agents.protocols import AgentRole, AgentOutput, AgentDecision


class StructuredLogLevel(Enum):
    """ç»“æ„åŒ–æ—¥å¿—çº§åˆ«"""
    DEBUG = "debug"
    INFO = "info"
    ANALYSIS = "analysis"
    DECISION = "decision" 
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"


class LogCategory(Enum):
    """æ—¥å¿—åˆ†ç±»"""
    SYSTEM = "system"
    AGENT = "agent"
    PIPELINE = "pipeline"
    MARKET_DATA = "market_data"
    TRADING = "trading"
    RISK = "risk"
    PERFORMANCE = "performance"


@dataclass
class StructuredLogEntry:
    """ç»“æ„åŒ–æ—¥å¿—æ¡ç›®"""
    timestamp: str
    level: str
    category: str
    component: str
    message: str
    data: Dict[str, Any]
    metadata: Dict[str, Any]
    trace_id: Optional[str] = None
    span_id: Optional[str] = None
    parent_span_id: Optional[str] = None


class DualFormatLogger:
    """
    åŒæ ¼å¼ç»“æ„åŒ–æ—¥å¿—è®°å½•å™¨
    
    åŠŸèƒ½ï¼š
    - JSONæ ¼å¼ï¼šç»“æ„åŒ–æ•°æ®ï¼Œä¾¿äºç¨‹åºè§£æå’Œç›‘æ§
    - Markdownæ ¼å¼ï¼šäººç±»å¯è¯»ï¼Œä¾¿äºè°ƒè¯•å’ŒæŠ¥å‘Šç”Ÿæˆ
    - å¼‚æ­¥å†™å…¥ï¼šæé«˜æ€§èƒ½ï¼Œé¿å…é˜»å¡ä¸»çº¿ç¨‹
    - çº¿ç¨‹å®‰å…¨ï¼šæ”¯æŒå¹¶å‘åœºæ™¯ä¸‹çš„æ—¥å¿—è®°å½•
    - åˆ†ç±»ç®¡ç†ï¼šæŒ‰ç»„ä»¶å’Œç±»åˆ«ç»„ç»‡æ—¥å¿—
    """
    
    def __init__(
        self,
        log_dir: str = "logs/structured",
        session_id: Optional[str] = None,
        enable_json: bool = True,
        enable_markdown: bool = True,
        enable_console: bool = True,
        async_mode: bool = True,
        buffer_size: int = 1000
    ):
        """
        åˆå§‹åŒ–åŒæ ¼å¼æ—¥å¿—è®°å½•å™¨
        
        Args:
            log_dir: æ—¥å¿—è¾“å‡ºç›®å½•
            session_id: ä¼šè¯ID
            enable_json: æ˜¯å¦å¯ç”¨JSONæ ¼å¼è¾“å‡º
            enable_markdown: æ˜¯å¦å¯ç”¨Markdownæ ¼å¼è¾“å‡º
            enable_console: æ˜¯å¦å¯ç”¨æ§åˆ¶å°è¾“å‡º
            async_mode: æ˜¯å¦å¯ç”¨å¼‚æ­¥æ¨¡å¼
            buffer_size: ç¼“å†²åŒºå¤§å°
        """
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(parents=True, exist_ok=True)
        
        self.session_id = session_id or self._generate_session_id()
        self.enable_json = enable_json
        self.enable_markdown = enable_markdown
        self.enable_console = enable_console
        self.async_mode = async_mode
        
        # åˆ›å»ºè¾“å‡ºæ–‡ä»¶
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.json_file = self.log_dir / f"session_{self.session_id}_{timestamp}.json"
        self.markdown_file = self.log_dir / f"session_{self.session_id}_{timestamp}.md"
        
        # åˆå§‹åŒ–Markdownæ–‡ä»¶å¤´
        if self.enable_markdown:
            self._initialize_markdown_file()
        
        # è®¾ç½®å¼‚æ­¥é˜Ÿåˆ—å’Œå†™å…¥å™¨
        self.log_queue = queue.Queue(maxsize=buffer_size) if async_mode else None
        self.writer_executor = ThreadPoolExecutor(max_workers=1, thread_name_prefix="LogWriter") if async_mode else None
        self.shutdown_flag = threading.Event()
        
        if async_mode:
            self.writer_executor.submit(self._async_writer_worker)
        
        # æ—¥å¿—è®¡æ•°å™¨
        self.entry_counter = 0
        self.lock = threading.Lock()
        
        # æ ‡å‡†æ—¥å¿—è®°å½•å™¨
        self.logger = logging.getLogger(f"StructuredLogger.{self.session_id}")
        self.logger.setLevel(logging.DEBUG)
    
    def _generate_session_id(self) -> str:
        """ç”Ÿæˆä¼šè¯ID"""
        return datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
    
    def _initialize_markdown_file(self):
        """åˆå§‹åŒ–Markdownæ–‡ä»¶å¤´"""
        header = f"""# TradingAgents ç»“æ„åŒ–æ—¥å¿—

**ä¼šè¯ID**: `{self.session_id}`  
**å¼€å§‹æ—¶é—´**: `{datetime.now().isoformat()}`  
**æ—¥å¿—çº§åˆ«**: DEBUG, INFO, ANALYSIS, DECISION, WARNING, ERROR, CRITICAL  

---

"""
        with open(self.markdown_file, 'w', encoding='utf-8') as f:
            f.write(header)
    
    def log(
        self,
        level: Union[StructuredLogLevel, str],
        category: Union[LogCategory, str],
        component: str,
        message: str,
        data: Optional[Dict[str, Any]] = None,
        metadata: Optional[Dict[str, Any]] = None,
        trace_id: Optional[str] = None,
        span_id: Optional[str] = None,
        parent_span_id: Optional[str] = None
    ):
        """
        è®°å½•ç»“æ„åŒ–æ—¥å¿—
        
        Args:
            level: æ—¥å¿—çº§åˆ«
            category: æ—¥å¿—åˆ†ç±»
            component: ç»„ä»¶åç§°
            message: æ—¥å¿—æ¶ˆæ¯
            data: ç»“æ„åŒ–æ•°æ®
            metadata: å…ƒæ•°æ®
            trace_id: è¿½è¸ªID
            span_id: è·¨åº¦ID
            parent_span_id: çˆ¶è·¨åº¦ID
        """
        with self.lock:
            self.entry_counter += 1
        
        # æ ‡å‡†åŒ–å‚æ•°
        if isinstance(level, str):
            level = StructuredLogLevel(level.lower())
        if isinstance(category, str):
            category = LogCategory(category.lower())
        
        # åˆ›å»ºæ—¥å¿—æ¡ç›®
        entry = StructuredLogEntry(
            timestamp=datetime.now().isoformat(),
            level=level.value,
            category=category.value,
            component=component,
            message=message,
            data=data or {},
            metadata={
                "entry_id": self.entry_counter,
                "session_id": self.session_id,
                "thread_id": threading.current_thread().name,
                **(metadata or {})
            },
            trace_id=trace_id,
            span_id=span_id,
            parent_span_id=parent_span_id
        )
        
        # è¾“å‡ºåˆ°ä¸åŒæ ¼å¼
        if self.async_mode:
            try:
                self.log_queue.put(entry, timeout=1.0)
            except queue.Full:
                # é˜Ÿåˆ—æ»¡æ—¶åŒæ­¥å†™å…¥
                self._write_entry_sync(entry)
        else:
            self._write_entry_sync(entry)
        
        # æ§åˆ¶å°è¾“å‡º
        if self.enable_console:
            self._console_output(entry)
    
    def log_agent_output(self, agent_output: AgentOutput, component: str = "agent"):
        """è®°å½•æ™ºèƒ½ä½“è¾“å‡º"""
        self.log(
            level=StructuredLogLevel.ANALYSIS,
            category=LogCategory.AGENT,
            component=f"{component}.{agent_output.role.lower()}",
            message=f"æ™ºèƒ½ä½“ {agent_output.role} å®Œæˆåˆ†æ",
            data={
                "symbol": agent_output.symbol,
                "score": agent_output.score,
                "confidence": agent_output.confidence,
                "decision": agent_output.decision.model_dump(mode='json') if agent_output.decision else None,
                "features": agent_output.features,
                "rationale": agent_output.rationale,
                "alerts": agent_output.alerts,
                "tags": agent_output.tags
            },
            metadata={
                "agent_id": agent_output.metadata.agent_id if agent_output.metadata else None,
                "execution_time_ms": agent_output.metadata.execution_time_ms if agent_output.metadata else None
            }
        )
    
    def log_pipeline_stage(
        self,
        stage: str,
        status: str,
        results: Dict[str, Any],
        duration_ms: Optional[int] = None
    ):
        """è®°å½•æµæ°´çº¿é˜¶æ®µ"""
        self.log(
            level=StructuredLogLevel.INFO,
            category=LogCategory.PIPELINE,
            component="orchestrator",
            message=f"æµæ°´çº¿é˜¶æ®µ {stage} {status}",
            data={
                "stage": stage,
                "status": status,
                "results": results,
                "duration_ms": duration_ms
            }
        )
    
    def log_decision(
        self,
        decision: AgentDecision,
        context: str,
        component: str = "decision_engine"
    ):
        """è®°å½•å†³ç­–"""
        self.log(
            level=StructuredLogLevel.DECISION,
            category=LogCategory.TRADING,
            component=component,
            message=f"äº¤æ˜“å†³ç­–: {decision.action.value}",
            data={
                "action": decision.action.value,
                "weight": decision.weight,
                "confidence": decision.confidence,
                "reasoning": decision.reasoning,
                "risk_level": decision.risk_level,
                "expected_return": decision.expected_return,
                "max_loss": decision.max_loss,
                "time_horizon": decision.time_horizon,
                "context": context
            }
        )
    
    def log_error(
        self,
        component: str,
        error: Exception,
        context: Optional[Dict[str, Any]] = None
    ):
        """è®°å½•é”™è¯¯"""
        self.log(
            level=StructuredLogLevel.ERROR,
            category=LogCategory.SYSTEM,
            component=component,
            message=f"é”™è¯¯: {str(error)}",
            data={
                "error_type": type(error).__name__,
                "error_message": str(error),
                "traceback": traceback.format_exc(),
                "context": context or {}
            }
        )
    
    def log_performance(
        self,
        component: str,
        metric: str,
        value: float,
        unit: str = "",
        additional_data: Optional[Dict[str, Any]] = None
    ):
        """è®°å½•æ€§èƒ½æŒ‡æ ‡"""
        self.log(
            level=StructuredLogLevel.INFO,
            category=LogCategory.PERFORMANCE,
            component=component,
            message=f"æ€§èƒ½æŒ‡æ ‡: {metric} = {value}{unit}",
            data={
                "metric": metric,
                "value": value,
                "unit": unit,
                **(additional_data or {})
            }
        )
    
    def _write_entry_sync(self, entry: StructuredLogEntry):
        """åŒæ­¥å†™å…¥æ—¥å¿—æ¡ç›®"""
        try:
            # å†™å…¥JSONæ ¼å¼
            if self.enable_json:
                self._write_json_entry(entry)
            
            # å†™å…¥Markdownæ ¼å¼
            if self.enable_markdown:
                self._write_markdown_entry(entry)
                
        except Exception as e:
            # è®°å½•å†™å…¥é”™è¯¯ï¼ˆé¿å…æ— é™é€’å½’ï¼‰
            print(f"æ—¥å¿—å†™å…¥é”™è¯¯: {e}")
    
    def _write_json_entry(self, entry: StructuredLogEntry):
        """å†™å…¥JSONæ ¼å¼æ—¥å¿—"""
        entry_dict = asdict(entry)
        json_line = json.dumps(entry_dict, ensure_ascii=False) + '\n'
        
        with open(self.json_file, 'a', encoding='utf-8') as f:
            f.write(json_line)
            f.flush()
    
    def _write_markdown_entry(self, entry: StructuredLogEntry):
        """å†™å…¥Markdownæ ¼å¼æ—¥å¿—"""
        # æ ¹æ®æ—¥å¿—çº§åˆ«é€‰æ‹©å›¾æ ‡
        level_icons = {
            "debug": "ğŸ”",
            "info": "â„¹ï¸",
            "analysis": "ğŸ“Š",
            "decision": "âš¡",
            "warning": "âš ï¸",
            "error": "âŒ",
            "critical": "ğŸš¨"
        }
        
        icon = level_icons.get(entry.level, "ğŸ“")
        timestamp = datetime.fromisoformat(entry.timestamp).strftime("%H:%M:%S")
        
        markdown_content = f"""
## {icon} {entry.level.upper()} - {entry.component}

**æ—¶é—´**: `{timestamp}`  
**ç±»åˆ«**: `{entry.category}`  
**æ¶ˆæ¯**: {entry.message}  
"""
        
        # æ·»åŠ ç»“æ„åŒ–æ•°æ®
        if entry.data:
            markdown_content += "\n**æ•°æ®**:\n```json\n"
            markdown_content += json.dumps(entry.data, ensure_ascii=False, indent=2)
            markdown_content += "\n```\n"
        
        # æ·»åŠ å…ƒæ•°æ®
        if entry.metadata and any(k not in ["entry_id", "session_id", "thread_id"] for k in entry.metadata.keys()):
            filtered_metadata = {k: v for k, v in entry.metadata.items() 
                               if k not in ["entry_id", "session_id", "thread_id"]}
            if filtered_metadata:
                markdown_content += "\n**å…ƒæ•°æ®**:\n```json\n"
                markdown_content += json.dumps(filtered_metadata, ensure_ascii=False, indent=2)
                markdown_content += "\n```\n"
        
        markdown_content += "\n---\n"
        
        with open(self.markdown_file, 'a', encoding='utf-8') as f:
            f.write(markdown_content)
            f.flush()
    
    def _console_output(self, entry: StructuredLogEntry):
        """æ§åˆ¶å°è¾“å‡º"""
        timestamp = datetime.fromisoformat(entry.timestamp).strftime("%H:%M:%S")
        level_colors = {
            "debug": "\033[36m",    # é’è‰²
            "info": "\033[37m",     # ç™½è‰²
            "analysis": "\033[32m", # ç»¿è‰²
            "decision": "\033[33m", # é»„è‰²
            "warning": "\033[93m",  # äº®é»„è‰²
            "error": "\033[91m",    # äº®çº¢è‰²
            "critical": "\033[95m"  # äº®ç´«è‰²
        }
        reset = "\033[0m"
        
        color = level_colors.get(entry.level, "\033[37m")
        print(f"{color}[{timestamp}] {entry.level.upper()} {entry.component}: {entry.message}{reset}")
        
        if entry.data and entry.level in ["error", "critical"]:
            print(f"  æ•°æ®: {json.dumps(entry.data, ensure_ascii=False, indent=2)}")
    
    def _async_writer_worker(self):
        """å¼‚æ­¥å†™å…¥å™¨å·¥ä½œçº¿ç¨‹"""
        while not self.shutdown_flag.is_set():
            try:
                entry = self.log_queue.get(timeout=1.0)
                if entry is None:  # åœæ­¢ä¿¡å·
                    break
                self._write_entry_sync(entry)
                self.log_queue.task_done()
            except queue.Empty:
                continue
            except Exception as e:
                print(f"å¼‚æ­¥æ—¥å¿—å†™å…¥é”™è¯¯: {e}")
    
    def close(self):
        """å…³é—­æ—¥å¿—è®°å½•å™¨"""
        if self.async_mode:
            # åœæ­¢å¼‚æ­¥å†™å…¥å™¨
            self.shutdown_flag.set()
            if self.log_queue:
                self.log_queue.put(None)  # å‘é€åœæ­¢ä¿¡å·
            
            # ç­‰å¾…é˜Ÿåˆ—æ¸…ç©º
            if self.log_queue:
                self.log_queue.join()
            
            # å…³é—­æ‰§è¡Œå™¨
            if self.writer_executor:
                self.writer_executor.shutdown(wait=True)
        
        # å†™å…¥Markdownæ–‡ä»¶å°¾
        if self.enable_markdown:
            with open(self.markdown_file, 'a', encoding='utf-8') as f:
                f.write(f"\n---\n**ç»“æŸæ—¶é—´**: `{datetime.now().isoformat()}`\n")
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()


# å…¨å±€ç»“æ„åŒ–æ—¥å¿—è®°å½•å™¨å®ä¾‹
_global_structured_logger: Optional[DualFormatLogger] = None
_logger_lock = threading.Lock()


def get_structured_logger(
    session_id: Optional[str] = None,
    **kwargs
) -> DualFormatLogger:
    """è·å–å…¨å±€ç»“æ„åŒ–æ—¥å¿—è®°å½•å™¨"""
    global _global_structured_logger
    
    with _logger_lock:
        if _global_structured_logger is None:
            _global_structured_logger = DualFormatLogger(
                session_id=session_id,
                **kwargs
            )
    
    return _global_structured_logger


def close_structured_logger():
    """å…³é—­å…¨å±€ç»“æ„åŒ–æ—¥å¿—è®°å½•å™¨"""
    global _global_structured_logger
    
    with _logger_lock:
        if _global_structured_logger is not None:
            _global_structured_logger.close()
            _global_structured_logger = None


# ä¾¿æ·å‡½æ•°
def log_debug(component: str, message: str, data: Optional[Dict[str, Any]] = None, **kwargs):
    """è®°å½•è°ƒè¯•æ—¥å¿—"""
    get_structured_logger().log(StructuredLogLevel.DEBUG, LogCategory.SYSTEM, component, message, data, **kwargs)


def log_info(component: str, message: str, data: Optional[Dict[str, Any]] = None, **kwargs):
    """è®°å½•ä¿¡æ¯æ—¥å¿—"""
    get_structured_logger().log(StructuredLogLevel.INFO, LogCategory.SYSTEM, component, message, data, **kwargs)


def log_analysis(component: str, message: str, data: Optional[Dict[str, Any]] = None, **kwargs):
    """è®°å½•åˆ†ææ—¥å¿—"""
    get_structured_logger().log(StructuredLogLevel.ANALYSIS, LogCategory.AGENT, component, message, data, **kwargs)


def log_decision(component: str, message: str, data: Optional[Dict[str, Any]] = None, **kwargs):
    """è®°å½•å†³ç­–æ—¥å¿—"""
    get_structured_logger().log(StructuredLogLevel.DECISION, LogCategory.TRADING, component, message, data, **kwargs)


def log_warning(component: str, message: str, data: Optional[Dict[str, Any]] = None, **kwargs):
    """è®°å½•è­¦å‘Šæ—¥å¿—"""
    get_structured_logger().log(StructuredLogLevel.WARNING, LogCategory.SYSTEM, component, message, data, **kwargs)


def log_error(component: str, error: Union[str, Exception], data: Optional[Dict[str, Any]] = None, **kwargs):
    """è®°å½•é”™è¯¯æ—¥å¿—"""
    if isinstance(error, Exception):
        get_structured_logger().log_error(component, error, data)
    else:
        get_structured_logger().log(StructuredLogLevel.ERROR, LogCategory.SYSTEM, component, str(error), data, **kwargs)